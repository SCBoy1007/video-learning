#!/usr/bin/env python3
"""
æœåŠ¡å™¨ç¯å¢ƒä¿¡æ¯æ”¶é›†è„šæœ¬
ç”¨äºVideo-Learningé¡¹ç›®éƒ¨ç½²å‰çš„ç¯å¢ƒæ£€æŸ¥å’Œè°ƒè¯•
"""

import sys
import os
import platform
import subprocess
import json
import datetime
import socket
from pathlib import Path


class ServerEnvChecker:
    def __init__(self):
        self.report = {}
        self.timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    def run_command(self, cmd, shell=True):
        """å®‰å…¨åœ°è¿è¡Œå‘½ä»¤å¹¶è¿”å›è¾“å‡º"""
        try:
            result = subprocess.run(
                cmd, shell=shell, capture_output=True, text=True, timeout=10
            )
            return result.stdout.strip(), result.returncode == 0
        except (subprocess.TimeoutExpired, subprocess.SubprocessError):
            return "Command failed or timed out", False

    def check_system_info(self):
        """æ”¶é›†ç³»ç»ŸåŸºæœ¬ä¿¡æ¯"""
        print("ğŸ” æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯...")

        self.report['system'] = {
            'hostname': socket.gethostname(),
            'platform': platform.platform(),
            'os': platform.system(),
            'os_release': platform.release(),
            'architecture': platform.machine(),
            'processor': platform.processor(),
            'python_version': sys.version,
            'timestamp': self.timestamp
        }

        # ç³»ç»Ÿè¿è¡Œæ—¶é—´
        uptime, _ = self.run_command("uptime")
        self.report['system']['uptime'] = uptime

        # å†…æ ¸ç‰ˆæœ¬
        kernel, _ = self.run_command("uname -r")
        self.report['system']['kernel'] = kernel

    def check_hardware_info(self):
        """æ”¶é›†ç¡¬ä»¶ä¿¡æ¯"""
        print("ğŸ–¥ï¸  æ£€æŸ¥ç¡¬ä»¶ä¿¡æ¯...")

        hardware = {}

        # CPUä¿¡æ¯
        cpu_info, _ = self.run_command("lscpu | grep -E '(Model name|Core|Thread|CPU MHz)'")
        hardware['cpu'] = cpu_info.split('\n') if cpu_info else ["CPU info not available"]

        # å†…å­˜ä¿¡æ¯
        mem_info, _ = self.run_command("free -h")
        hardware['memory'] = mem_info

        # ç£ç›˜ä½¿ç”¨æƒ…å†µ
        disk_info, _ = self.run_command("df -h")
        hardware['disk_usage'] = disk_info

        self.report['hardware'] = hardware

    def check_gpu_info(self):
        """æ”¶é›†GPUä¿¡æ¯"""
        print("ğŸ® æ£€æŸ¥GPUä¿¡æ¯...")

        gpu = {}

        # NVIDIA GPUä¿¡æ¯
        nvidia_smi, success = self.run_command("nvidia-smi")
        if success:
            gpu['nvidia_smi'] = nvidia_smi

            # GPUè¯¦ç»†ä¿¡æ¯
            gpu_details, _ = self.run_command(
                "nvidia-smi --query-gpu=name,memory.total,memory.used,memory.free,utilization.gpu --format=csv"
            )
            gpu['gpu_details'] = gpu_details
        else:
            gpu['nvidia_smi'] = "NVIDIA GPU not detected or nvidia-smi not available"

        # CUDAç‰ˆæœ¬
        cuda_version, _ = self.run_command("nvcc --version")
        gpu['cuda_version'] = cuda_version if cuda_version else "CUDA not available"

        # NVIDIAé©±åŠ¨ç‰ˆæœ¬
        driver_version, _ = self.run_command("cat /proc/driver/nvidia/version")
        gpu['driver_version'] = driver_version if driver_version else "NVIDIA driver info not available"

        self.report['gpu'] = gpu

    def check_python_env(self):
        """æ£€æŸ¥Pythonç¯å¢ƒ"""
        print("ğŸ æ£€æŸ¥Pythonç¯å¢ƒ...")

        python_env = {
            'python_executable': sys.executable,
            'python_path': sys.path[:5],  # åªæ˜¾ç¤ºå‰5ä¸ªè·¯å¾„
            'virtual_env': os.environ.get('VIRTUAL_ENV', 'Not in virtual environment'),
            'conda_env': os.environ.get('CONDA_DEFAULT_ENV', 'Not in conda environment')
        }

        # Condaä¿¡æ¯
        conda_info, success = self.run_command("conda info --envs")
        if success:
            python_env['conda_envs'] = conda_info

        self.report['python_env'] = python_env

    def check_ml_packages(self):
        """æ£€æŸ¥æœºå™¨å­¦ä¹ ç›¸å…³åŒ…ç‰ˆæœ¬"""
        print("ğŸ“¦ æ£€æŸ¥MLåŒ…ç‰ˆæœ¬...")

        packages_to_check = [
            'torch', 'torchvision', 'transformers', 'datasets', 'accelerate',
            'numpy', 'pandas', 'pillow', 'wandb', 'ray', 'vllm'
        ]

        package_info = {}

        for package in packages_to_check:
            try:
                __import__(package)
                version_cmd = f"python -c \"import {package}; print({package}.__version__)\""
                version, success = self.run_command(version_cmd)
                package_info[package] = version if success else "Version check failed"
            except ImportError:
                package_info[package] = "Not installed"

        self.report['ml_packages'] = package_info

        # pip list å…³é”®åŒ…
        pip_list, _ = self.run_command("pip list | grep -E '(torch|transform|dataset|accelerate|wandb|ray|vllm)'")
        self.report['pip_packages'] = pip_list

    def check_network_storage(self):
        """æ£€æŸ¥ç½‘ç»œå’Œå­˜å‚¨"""
        print("ğŸŒ æ£€æŸ¥ç½‘ç»œå’Œå­˜å‚¨...")

        network_storage = {}

        # ç½‘ç»œæ¥å£
        interfaces, _ = self.run_command("ip addr show")
        network_storage['network_interfaces'] = interfaces

        # äº’è”ç½‘è¿æ¥æµ‹è¯•
        ping_test, success = self.run_command("ping -c 1 google.com")
        network_storage['internet_connectivity'] = "Connected" if success else "Connection failed"

        # æ£€æŸ¥æ•°æ®ç›®å½•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        data_dirs = ['data/', '/data/', '/mnt/data/', 'datasets/']
        existing_dirs = []
        for dir_path in data_dirs:
            if os.path.exists(dir_path):
                size_cmd = f"du -sh {dir_path}"
                size_info, _ = self.run_command(size_cmd)
                existing_dirs.append(f"{dir_path}: {size_info}")

        network_storage['data_directories'] = existing_dirs

        # æŒ‚è½½ç‚¹
        mounts, _ = self.run_command("mount | grep -E '(ext4|xfs|nfs)'")
        network_storage['mounts'] = mounts

        self.report['network_storage'] = network_storage

    def check_resources(self):
        """æ£€æŸ¥å½“å‰èµ„æºä½¿ç”¨"""
        print("ğŸ“Š æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ...")

        resources = {}

        # CPUå’Œå†…å­˜ä½¿ç”¨
        top_info, _ = self.run_command("top -bn1 | head -15")
        resources['current_usage'] = top_info

        # GPUä½¿ç”¨æƒ…å†µ
        if 'nvidia_smi' in self.report.get('gpu', {}):
            gpu_usage, _ = self.run_command("nvidia-smi -q -d UTILIZATION,MEMORY")
            resources['gpu_usage'] = gpu_usage

        # ç›¸å…³è¿›ç¨‹
        python_processes, _ = self.run_command("ps aux | grep python | head -10")
        resources['python_processes'] = python_processes

        self.report['resources'] = resources

    def check_project_requirements(self):
        """æ£€æŸ¥é¡¹ç›®ç‰¹å®šéœ€æ±‚"""
        print("ğŸ¯ æ£€æŸ¥é¡¹ç›®ç‰¹å®šéœ€æ±‚...")

        project = {}

        # æ£€æŸ¥å½“å‰ç›®å½•
        current_dir = os.getcwd()
        project['current_directory'] = current_dir
        project['directory_contents'] = os.listdir(current_dir)[:20]  # å‰20ä¸ªæ–‡ä»¶

        # æ£€æŸ¥requirements.txt
        if os.path.exists('requirements.txt'):
            with open('requirements.txt', 'r') as f:
                project['requirements'] = f.read()

        # æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹ç›®å½•
        model_dirs = ['pretrained_models/', 'models/', '/models/']
        for model_dir in model_dirs:
            if os.path.exists(model_dir):
                models, _ = self.run_command(f"ls -la {model_dir}")
                project[f'models_in_{model_dir}'] = models

        # æ£€æŸ¥CUDA_VISIBLE_DEVICES
        project['cuda_visible_devices'] = os.environ.get('CUDA_VISIBLE_DEVICES', 'Not set')

        self.report['project'] = project

    def generate_report(self):
        """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
        print("ğŸ“‹ ç”Ÿæˆç¯å¢ƒæŠ¥å‘Š...")

        # è¿è¡Œæ‰€æœ‰æ£€æŸ¥
        self.check_system_info()
        self.check_hardware_info()
        self.check_gpu_info()
        self.check_python_env()
        self.check_ml_packages()
        self.check_network_storage()
        self.check_resources()
        self.check_project_requirements()

        return self.report

    def save_report(self, filename=None):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if filename is None:
            hostname = socket.gethostname()
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"server_env_report_{hostname}_{timestamp}.json"

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, indent=2, ensure_ascii=False)

        return filename

    def print_summary(self):
        """æ‰“å°å…³é”®ä¿¡æ¯æ‘˜è¦"""
        print("\n" + "="*80)
        print("ğŸš€ æœåŠ¡å™¨ç¯å¢ƒæ£€æŸ¥æ‘˜è¦")
        print("="*80)

        # ç³»ç»Ÿä¿¡æ¯
        sys_info = self.report.get('system', {})
        print(f"ğŸ–¥ï¸  ä¸»æœº: {sys_info.get('hostname', 'Unknown')}")
        print(f"ğŸ§ ç³»ç»Ÿ: {sys_info.get('platform', 'Unknown')}")

        # GPUä¿¡æ¯
        gpu_info = self.report.get('gpu', {})
        if 'nvidia-smi not available' not in gpu_info.get('nvidia_smi', ''):
            gpu_details = gpu_info.get('gpu_details', '')
            if gpu_details:
                gpu_lines = gpu_details.split('\n')[1:]  # è·³è¿‡æ ‡é¢˜
                print(f"ğŸ® GPUä¿¡æ¯:")
                for line in gpu_lines:
                    if line.strip():
                        print(f"    {line}")

        # Pythonå’Œå…³é”®åŒ…
        python_env = self.report.get('python_env', {})
        print(f"ğŸ Python: {python_env.get('python_executable', 'Unknown')}")
        print(f"ğŸ“¦ ç¯å¢ƒ: {python_env.get('conda_env', python_env.get('virtual_env', 'Unknown'))}")

        # å…³é”®åŒ…ç‰ˆæœ¬
        ml_packages = self.report.get('ml_packages', {})
        key_packages = ['torch', 'transformers', 'datasets', 'wandb']
        print("ğŸ“¦ å…³é”®åŒ…ç‰ˆæœ¬:")
        for pkg in key_packages:
            version = ml_packages.get(pkg, 'Not found')
            print(f"    {pkg}: {version}")

        print("="*80)


def main():
    print("ğŸ”¥ Video-Learning æœåŠ¡å™¨ç¯å¢ƒæ£€æŸ¥å·¥å…·")
    print("="*80)

    checker = ServerEnvChecker()
    report = checker.generate_report()

    # ä¿å­˜æŠ¥å‘Š
    report_file = checker.save_report()
    print(f"\nâœ… å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    # æ‰“å°æ‘˜è¦
    checker.print_summary()

    print(f"\nğŸ’¡ å»ºè®®:")
    print("1. æ£€æŸ¥GPUå’ŒCUDAæ˜¯å¦æ­£ç¡®å®‰è£…")
    print("2. ç¡®è®¤æ‰€éœ€PythonåŒ…ç‰ˆæœ¬æ˜¯å¦åŒ¹é…")
    print("3. éªŒè¯æ•°æ®ç›®å½•å’Œæ¨¡å‹ç›®å½•æ˜¯å¦å¯è®¿é—®")
    print("4. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ï¼ˆä¸‹è½½æ¨¡å‹éœ€è¦ï¼‰")


if __name__ == "__main__":
    main()