#!/usr/bin/env python3
"""
ä¿®å¤æ•°æ®é›†åæ ‡ç³»ç»Ÿä¸ä¸€è‡´é—®é¢˜

å°†åŸå§‹ä½“ç´ åæ ‡è½¬æ¢ä¸ºè§†é¢‘åƒç´ åæ ‡ï¼Œè§£å†³è®­ç»ƒæ—¶åæ ‡ç³»ä¸åŒ¹é…çš„é—®é¢˜
- MSD: 240Ã—240Ã—155 â†’ 252Ã—252Ã—155 (video: 1008Ã—252)
- BraTS: 182Ã—218Ã—182 â†’ 196Ã—224Ã—182 (video: 784Ã—224)
"""

import os
import json
import shutil
import argparse
from pathlib import Path
from typing import Dict, List, Tuple
from datasets import load_from_disk
import numpy as np


class DatasetCoordinateFixer:
    def __init__(self, data_dir: str, backup: bool = True, validate: bool = True):
        self.data_dir = Path(data_dir)
        self.backup = backup
        self.validate = validate

        # æ•°æ®é›†é…ç½®
        self.dataset_configs = {
            'MSD_T1_MRI_video': {
                'original_shape': [240, 240, 155],
                'video_shape': [252, 252, 155],
                'video_size': [1008, 252],  # 4æ¨¡æ€æ‹¼æ¥
                'scale_factors': [252/240, 252/240, 1.0]
            },
            'BraTS_GLI_TrainingData_video': {
                'original_shape': [182, 218, 182],
                'video_shape': [196, 224, 182],
                'video_size': [784, 224],  # 4æ¨¡æ€æ‹¼æ¥
                'scale_factors': [196/182, 224/218, 1.0]
            },
            'BraTS_GLI_TrainingData_Additional_video': {
                'original_shape': [182, 218, 182],
                'video_shape': [196, 224, 182],
                'video_size': [784, 224],  # 4æ¨¡æ€æ‹¼æ¥
                'scale_factors': [196/182, 224/218, 1.0]
            }
        }

        self.conversion_stats = {}

    def backup_dataset(self, dataset_name: str) -> bool:
        """å¤‡ä»½åŸå§‹æ•°æ®é›†"""
        original_path = self.data_dir / dataset_name
        backup_path = self.data_dir / f"{dataset_name}_backup"

        if not original_path.exists():
            print(f"âŒ æ•°æ®é›†ä¸å­˜åœ¨: {original_path}")
            return False

        if backup_path.exists():
            print(f"âš ï¸  å¤‡ä»½å·²å­˜åœ¨: {backup_path}")
            return True

        try:
            print(f"ğŸ“‚ å¤‡ä»½æ•°æ®é›†: {original_path} â†’ {backup_path}")
            shutil.copytree(original_path, backup_path)
            return True
        except Exception as e:
            print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
            return False

    def convert_bbox_coordinates(self, bbox: List[float], scale_factors: List[float]) -> List[int]:
        """è½¬æ¢3Dè¾¹ç•Œæ¡†åæ ‡"""
        if len(bbox) != 6:
            raise ValueError(f"Invalid bbox format: {bbox}")

        # [x1, y1, z1, x2, y2, z2] æ ¼å¼
        converted = [
            int(bbox[0] * scale_factors[0]),  # x1
            int(bbox[1] * scale_factors[1]),  # y1
            int(bbox[2] * scale_factors[2]),  # z1
            int(bbox[3] * scale_factors[0]),  # x2
            int(bbox[4] * scale_factors[1]),  # y2
            int(bbox[5] * scale_factors[2])   # z2
        ]

        return converted

    def convert_dataset_coordinates(self, dataset_name: str) -> bool:
        """è½¬æ¢å•ä¸ªæ•°æ®é›†çš„åæ ‡"""
        print(f"\nğŸ”„ å¤„ç†æ•°æ®é›†: {dataset_name}")

        original_path = self.data_dir / dataset_name
        fixed_path = self.data_dir / f"{dataset_name}_fixed"

        if not original_path.exists():
            print(f"âŒ æ•°æ®é›†ä¸å­˜åœ¨: {original_path}")
            return False

        # è·å–é…ç½®
        config = self.dataset_configs[dataset_name]
        scale_factors = config['scale_factors']

        try:
            # åŠ è½½æ•°æ®é›†
            dataset = load_from_disk(str(original_path / 'train'))
            print(f"  ğŸ“Š åŠ è½½æ ·æœ¬æ•°: {len(dataset)}")

            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                'total_samples': len(dataset),
                'converted_samples': 0,
                'errors': 0,
                'bbox_changes': [],
                'coordinate_ranges': {'before': {}, 'after': {}}
            }

            def convert_sample_coordinates(example):
                """è½¬æ¢å•ä¸ªæ ·æœ¬çš„åæ ‡"""
                try:
                    # è§£æsolution
                    solution = json.loads(example['solution'])
                    if not isinstance(solution, list) or len(solution) == 0:
                        raise ValueError("Invalid solution format")

                    original_bbox = solution[0]['bbox_3d'].copy()

                    # è½¬æ¢bboxåæ ‡
                    converted_bbox = self.convert_bbox_coordinates(original_bbox, scale_factors)
                    solution[0]['bbox_3d'] = converted_bbox

                    # æ›´æ–°solution
                    example['solution'] = json.dumps(solution)

                    # æ·»åŠ å…ƒæ•°æ®
                    example['coordinate_system'] = 'video_pixels'
                    example['original_shape'] = str(config['original_shape'])
                    example['video_shape'] = str(config['video_shape'])
                    example['scale_factors'] = str(scale_factors)

                    # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                    original_volume = (
                        (original_bbox[3] - original_bbox[0]) *
                        (original_bbox[4] - original_bbox[1]) *
                        (original_bbox[5] - original_bbox[2])
                    )
                    converted_volume = (
                        (converted_bbox[3] - converted_bbox[0]) *
                        (converted_bbox[4] - converted_bbox[1]) *
                        (converted_bbox[5] - converted_bbox[2])
                    )

                    volume_change = converted_volume / original_volume if original_volume > 0 else 1.0

                    bbox_change = {
                        'original': original_bbox,
                        'converted': converted_bbox,
                        'volume_change': volume_change
                    }
                    stats['bbox_changes'].append(bbox_change)
                    stats['converted_samples'] += 1

                    return example

                except Exception as e:
                    print(f"    âŒ è½¬æ¢æ ·æœ¬å¤±è´¥: {e}")
                    stats['errors'] += 1
                    return example

            # åº”ç”¨åæ ‡è½¬æ¢
            print(f"  ğŸ”„ è½¬æ¢åæ ‡ç³»ç»Ÿ...")
            dataset_converted = dataset.map(convert_sample_coordinates)

            # ä¿å­˜è½¬æ¢åçš„æ•°æ®é›†
            print(f"  ğŸ’¾ ä¿å­˜åˆ°: {fixed_path}")
            dataset_converted.save_to_disk(str(fixed_path))

            # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
            self.conversion_stats[dataset_name] = stats

            print(f"  âœ… è½¬æ¢å®Œæˆ: {stats['converted_samples']}/{stats['total_samples']} æˆåŠŸ")
            if stats['errors'] > 0:
                print(f"    âš ï¸  é”™è¯¯æ•°: {stats['errors']}")

            return True

        except Exception as e:
            print(f"âŒ å¤„ç†æ•°æ®é›†å¤±è´¥: {e}")
            return False

    def validate_conversion(self, dataset_name: str) -> bool:
        """éªŒè¯è½¬æ¢ç»“æœ"""
        print(f"\nğŸ” éªŒè¯æ•°æ®é›†: {dataset_name}")

        fixed_path = self.data_dir / f"{dataset_name}_fixed"
        if not fixed_path.exists():
            print(f"âŒ è½¬æ¢åæ•°æ®é›†ä¸å­˜åœ¨: {fixed_path}")
            return False

        try:
            dataset = load_from_disk(str(fixed_path / 'train'))
            config = self.dataset_configs[dataset_name]

            # éªŒè¯æ ·æœ¬
            sample = dataset[0]
            solution = json.loads(sample['solution'])
            bbox = solution[0]['bbox_3d']

            # æ£€æŸ¥åæ ‡èŒƒå›´
            video_w, video_h = config['video_size']
            single_modal_w = video_w // 4  # å•æ¨¡æ€å®½åº¦
            single_modal_h = video_h

            x_valid = 0 <= bbox[0] < single_modal_w and 0 <= bbox[3] < single_modal_w
            y_valid = 0 <= bbox[1] < single_modal_h and 0 <= bbox[4] < single_modal_h
            z_valid = 0 <= bbox[2] < config['original_shape'][2] and 0 <= bbox[5] < config['original_shape'][2]

            print(f"  ğŸ“ åæ ‡èŒƒå›´éªŒè¯:")
            print(f"    Xåæ ‡: {'âœ…' if x_valid else 'âŒ'} (åº”åœ¨0-{single_modal_w})")
            print(f"    Yåæ ‡: {'âœ…' if y_valid else 'âŒ'} (åº”åœ¨0-{single_modal_h})")
            print(f"    Zåæ ‡: {'âœ…' if z_valid else 'âŒ'} (åº”åœ¨0-{config['original_shape'][2]})")

            # éªŒè¯å…ƒæ•°æ®
            has_metadata = all(key in sample for key in ['coordinate_system', 'original_shape', 'video_shape'])
            print(f"  ğŸ“‹ å…ƒæ•°æ®: {'âœ…' if has_metadata else 'âŒ'}")

            if has_metadata:
                print(f"    åæ ‡ç³»ç»Ÿ: {sample['coordinate_system']}")
                print(f"    åŸå§‹å½¢çŠ¶: {sample['original_shape']}")
                print(f"    è§†é¢‘å½¢çŠ¶: {sample['video_shape']}")

            return x_valid and y_valid and z_valid and has_metadata

        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return False

    def print_conversion_statistics(self):
        """æ‰“å°è½¬æ¢ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“Š è½¬æ¢ç»Ÿè®¡æŠ¥å‘Š")
        print("=" * 60)

        for dataset_name, stats in self.conversion_stats.items():
            print(f"\nğŸ“ {dataset_name}:")
            print(f"  æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
            print(f"  æˆåŠŸè½¬æ¢: {stats['converted_samples']}")
            print(f"  è½¬æ¢é”™è¯¯: {stats['errors']}")

            if len(stats['bbox_changes']) > 0:
                volume_changes = [change['volume_change'] for change in stats['bbox_changes'][:5]]
                avg_volume_change = np.mean(volume_changes)
                print(f"  å¹³å‡ä½“ç§¯å˜åŒ–: {avg_volume_change:.3f}x")

                # æ˜¾ç¤ºå‡ ä¸ªè½¬æ¢ç¤ºä¾‹
                print(f"  è½¬æ¢ç¤ºä¾‹:")
                for i, change in enumerate(stats['bbox_changes'][:3]):
                    orig = change['original']
                    conv = change['converted']
                    print(f"    [{i+1}] {orig} â†’ {conv}")

    def replace_original_datasets(self):
        """ç”¨ä¿®å¤åçš„æ•°æ®é›†æ›¿æ¢åŸå§‹æ•°æ®é›†"""
        print(f"\nğŸ”„ æ›¿æ¢åŸå§‹æ•°æ®é›†...")

        for dataset_name in self.dataset_configs.keys():
            original_path = self.data_dir / dataset_name
            fixed_path = self.data_dir / f"{dataset_name}_fixed"

            if not fixed_path.exists():
                print(f"âš ï¸  è·³è¿‡ {dataset_name}: ä¿®å¤ç‰ˆæœ¬ä¸å­˜åœ¨")
                continue

            try:
                # åˆ é™¤åŸå§‹ç‰ˆæœ¬
                if original_path.exists():
                    shutil.rmtree(original_path)

                # é‡å‘½åä¿®å¤ç‰ˆæœ¬
                shutil.move(str(fixed_path), str(original_path))
                print(f"âœ… {dataset_name}: æ›¿æ¢æˆåŠŸ")

            except Exception as e:
                print(f"âŒ {dataset_name}: æ›¿æ¢å¤±è´¥ - {e}")

    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„åæ ‡ä¿®å¤æµç¨‹"""
        print("ğŸš€ å¼€å§‹ä¿®å¤æ•°æ®é›†åæ ‡ç³»ç»Ÿ")
        print("=" * 60)

        success_count = 0
        total_datasets = len(self.dataset_configs)

        for dataset_name in self.dataset_configs.keys():
            print(f"\nğŸ“‚ å¤„ç†æ•°æ®é›† {dataset_name}")

            # 1. å¤‡ä»½åŸå§‹æ•°æ®
            if self.backup:
                if not self.backup_dataset(dataset_name):
                    continue

            # 2. è½¬æ¢åæ ‡
            if not self.convert_dataset_coordinates(dataset_name):
                continue

            # 3. éªŒè¯è½¬æ¢ç»“æœ
            if self.validate:
                if self.validate_conversion(dataset_name):
                    success_count += 1
                    print(f"âœ… {dataset_name}: å¤„ç†æˆåŠŸ")
                else:
                    print(f"âŒ {dataset_name}: éªŒè¯å¤±è´¥")
            else:
                success_count += 1

        # 4. æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        self.print_conversion_statistics()

        # 5. æ€»ç»“
        print(f"\nğŸ‰ å¤„ç†å®Œæˆ: {success_count}/{total_datasets} æ•°æ®é›†æˆåŠŸ")

        if success_count == total_datasets:
            try:
                replace = input("\næ˜¯å¦ç”¨ä¿®å¤åçš„æ•°æ®é›†æ›¿æ¢åŸå§‹æ•°æ®é›†? (y/N): ").strip().lower()
                if replace == 'y':
                    self.replace_original_datasets()
                    print("âœ… æ‰€æœ‰æ•°æ®é›†å·²æ›´æ–°ä¸ºä¿®å¤ç‰ˆæœ¬")
                else:
                    print("â„¹ï¸  ä¿®å¤åçš„æ•°æ®é›†ä¿å­˜ä¸º *_fixed ç‰ˆæœ¬")
            except EOFError:
                print("\nâ„¹ï¸  ä¿®å¤åçš„æ•°æ®é›†ä¿å­˜ä¸º *_fixed ç‰ˆæœ¬")


def main():
    parser = argparse.ArgumentParser(description="ä¿®å¤æ•°æ®é›†åæ ‡ç³»ç»Ÿ")
    parser.add_argument("--data-dir", default=".", help="æ•°æ®é›†ç›®å½•è·¯å¾„")
    parser.add_argument("--no-backup", action="store_true", help="è·³è¿‡å¤‡ä»½æ­¥éª¤")
    parser.add_argument("--no-validate", action="store_true", help="è·³è¿‡éªŒè¯æ­¥éª¤")
    parser.add_argument("--auto-replace", action="store_true", help="è‡ªåŠ¨æ›¿æ¢åŸå§‹æ•°æ®é›†")

    args = parser.parse_args()

    # åˆ›å»ºä¿®å¤å™¨
    fixer = DatasetCoordinateFixer(
        data_dir=args.data_dir,
        backup=not args.no_backup,
        validate=not args.no_validate
    )

    # æ‰§è¡Œä¿®å¤
    fixer.run()


if __name__ == "__main__":
    main()